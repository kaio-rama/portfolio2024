---
title: 'Algoritmos de busqueda en C'
publishedAt: '2024-09-17'
summary: 'Principios básicos, matematicos y fundamentales para comprender patrones algoritmicos en programación'
---

Cuando hablamos de la eficiencia de los algoritmos, simplemente desechamos las constantes. 
Esto nos puede dejar tanto "O" (big O notacion), la cúal es omnipresente en programación y particularmente cuando se habla del diseño de algún algoritmo.
Como también nos puede dejar con "Ω"(omega), la cúal representa el caso opuesto de O, es decir, si O la usamos para cuantificar cuanto es la mayor cantidad de pasos 
para completar un algoritmo. Omega representa la minima cantidad de pasos que nos puede llevar completar el mismo algoritmo. 

#### Tiempos de ejecución, de algoritmos, más comunes:

O(n**2) = cuadratic time.

O(n log n) = n log n time.

O(n) = linear time.

O(log n) = logaritmic time.

O(1) = constant time (constant number of steps).

Ω(n**2) 

Ω(n log n) 

Ω(n) 

Ω(log n) 

Ω(1) 

Sin embargo pueden existir casos donde la mayor cantidad de pasos posibles para completar un algoritmo ("O") y la menor ("Ω") sean la misma,
por ejemplo en un algoritmo donde queramos separ la cantidad de personas en un evento. En este caso siempre nos llevará la misma cantidad de pasos contabilizarlos a todos que sería n cantidad de veces.
Para estos casos usamos el simbolo Θ (Theta).

Θ(n**2) 

Θ(n log n) 

Θ(n)

Θ(log n)

Θ(log n)


```` JavaScript

n= number to cuantify. (ej: cantidad de x en a)
n**2= number x on a of doing b things.


````

#### EJEMPLOS EN LOGARITMOS DE BÚSQUEDA:

O(n) --> Linear Search ...

O(log n) --> Binary Search ...

Ω(1) --> linear search / Binary Search

